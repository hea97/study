# 개요

Amazon Slimple Storage Service(이하 S3) 일반 사용자, 애플리케이션 그리고 셀 수 없이 많은 AWS 서비스 위한 data 저장소.

- 아카이브, 로그 파일, 재난 복구 이미지
- 저장된 빅데이터 분석 업무 활용
- 정적 웹사이트 호스팅

S3 저렴하면서 신뢰할 수 있는 스토리지 서비스, AWS 내외부의 각종 리소스 긴밀하게 통합 사용

EC2 인스턴스의 OS 불륨이 블록 스토리지(block storage)인 반면 S3 좀 더 다양한 용도로 활용 무제한 용량 객체 스토리지(object storage) 점에서 차이 있음.

객체 스토리지와 블록 스토리지의 차이점

### **블록 스토리지**

https://aws.amazon.com/ko/what-is/block-storage/

Windows의 NTFS, Linux의 Btrfs, ext4과 같은 파일 시스템을 위해 물리적 저장 장치를 블록 단위로 나눈것을 의미.  
파일 시스템은 머신에 설치된 OS 주요 기능 중 하나,  
OS 작동에 필요한 data 읽어들이기 위해 관련 파일 data 저장 될 수 있는 공간 분할 및 할당 역할 담당

### 객체 스토리지

S3와 같은 객체 스토리지는 어떤 형식의 data라도 저장할 수 있는 공간.  
OS와 관련 복잡한 규칙이 반영된 블록 스토리지와 달리, 객체 스토리지는 권한 부여받은 누구나 접속해서 어떤 포맷 data, 어떤 용량의 data라도 저장. 

S3 파일을 저장, 2KB 용량의 메타data 함께 저장.  
S3 메타data는 data 퍼미션, 버킷 내 파일 시스템에서의 위치 등 정보를 키 형식으로 제공

# S3 서비스 아키텍처

S3 파일은 버킷에 저장.  
기본적으로 계정에서는 최대 100개의 버킷을 생성, 다른 AWS 서비스처럼 AWS측 가용 버킷 수 증가시킬 것 요청

S3 버킷 및 그 속 저장된 콘텐츠는 단일 AWS 리전에만 존재,  
버킷의 이름은 전세계 S3 시스템을 기준으로 유일한 것이 특징.  
버킷 이름에는 나름의 명명 규칙이 있다. 사용자 대부분은 운영 효율 및 법규 등의 준수를 위해 특정 지역의 리전을 선호. 반면, 버킷 일므에 특정 리전에 구체적으로 드러나는 것은 원치 않는 경우가 많음.

ex. HTTP 접근 방식으로 bucketname이라는 버킷 속 filename이라는 파일에 접근하기위한 URL.  

s3.amazonaws.com/bucketname/filename

위 URL 통해 해당 객체 접근 위한 적절한 접근 권한 부여.  
AWS CLI 이용한 파일 접근 코드는

s3://bucketname/filename

## 접두사 및 구분문자

S3 버킷 내 별도의 하위 폴더 계층 구조 없이 객체를 저장, 사용자는 좀 더 체계적으로 저장 객체를 관리 위해 버킷에 접두사 또는 구분문자를 추가 사용.

접두사는 스토리지 구조 레벨을 표기 위한 보통의 텍스트 문자열.   
ex. 구분문자 ‘/’ 다음에 contracts라는 단어를 추가해 contracts/acme.pdf와 같이 스토리지 구조에 이름을 붙인 뒤, 두 번째 파일에는 contracts/dyacme.pdf라는 이름 붙여 두개 파일을 그룹화.

S3 버킷 내 이와 같은 폴더 또는 디렉토리 구조를 인식해 해당 계층 구조에 따라 파일을 업로드 할 수 있음, 슬래시 기호는 자동으로 폴더 나타내는 구문문자로 변환.  
콘솔 또는 API 이용 S3 객체 자유롭게 접근할 수 있는 이유 중 하나 → 이와 같은 접두사와 구분문자 덕분.

## 대용량 객체 저장하기

이론적으로는 버킷에 저장할 수 있는 data의 총용량에는 제한이 없지만 객체 하나당 용량은 5TB를 초과할 수 없으며, 한 번의 업로드 작업은 5GB를 초과 할 수 없다  
→ 같은 용량 제한 문제를 피하기 위한 방법으로,  
AWS 100MB 초과 객체의 경우 멀티파트 업로드(Multipart Upload) 기능 사용 권장

멀티파트 업로드는 말 그대로, S3 하나의 대용량 파일을 업로드할 때 여러 개 부분으로 분리해 업로드하는 기능, 여러 부분 중 일부 업로드에 실패하더라도 반복적으로 업로드 작업을 수행한다는 특징.  
AWS CLI 또는 고수준 API S3에 업로드할 경우 멀티파트 업로드 기능이 자동 적용, 저수준 API S3에 업로드할 경우 직접 객체를 여러 부분으로 분할

Applicatoin Programming Interface(API)는 코드 or 명령줄 방식으로 각종 작업을 실행할 수 있는 프로그래밍 기법 인터페이스, AWS 각종 서비스에 대한 어드민 작업 방법 널리 활용.   
AWS 세심한 설정 필요한 S3 업로드 작업을 위해 저수준 API 제공, 좀 더 자동화 수준이 높은 S3 업르드 작업 위해 고수준 API 제공.

멀티파트 업로드에 대한 상세 설명

https://docs.aws.amazon.com/ko_kr/AmazonS3/latest/userguide/mpuoverview.html

S3 버킷에 대용량 파일을 전송해야 하는 경우  
Amazon S3 Transfer Acceleration 환경설정 통해 전송 속도 높임.  
버킷 Transfer Acceleration 기능을 사용하도록 설정한 경우,  
업로드 작업은 인근 AWS 엣지 로케이션과  Amazon의 내부 네트워크를 통해 고속 처림

Transfer Acceleration이 지역과 특정 AWS 리전 사이에서 실제로 얼마나 빠른 속도로 파일을 전송하는지 확인하려면 Amazon S3 Transfer Acceleration Speed Comparison 도구 이용

[AWS Amazon S3 Transfer Acceleration Speed Comparison](https://aws.amazon.com/ko/pm/serv-s3/?gclid=CjwKCAjwnK60BhA9EiwAmpHZw9N1sQxc_Phxv_Gnz1TGV8FFOAO7TMfElVC900wmpY3nB73Fda4NExoCJNoQAvD_BwE&trk=919c3162-c8f1-4d4c-baec-33fb3fcc1988&sc_channel=ps&ef_id=CjwKCAjwnK60BhA9EiwAmpHZw9N1sQxc_Phxv_Gnz1TGV8FFOAO7TMfElVC900wmpY3nB73Fda4NExoCJNoQAvD_BwE:G:s&s_kwcid=AL!4422!3!536393992474!p!!g!!amazon%20web%20services%20s3!11547526035!116491964350)

Transfer Acceleration 파일 전송에 확실하게 도움된다면, 버킷에서 이 기능을 활성화한 뒤 사용. → bucketname.s3-accelerate.amazonaws.com과 같이 특수한 엔드포인트 도멘인 네임으로 전송 경로 설정

## 암호화

웹사이트 경우 외부 공개하는 정보가 아닌 이상 S3 저장하는 data는 기본적으로 암호화를 할 필요 있음.  
S3 data 저장할 때는 암호화 키를 이용, Amazon 암호화된 API 엔드포인트를 이용해 S3 다른 서비스 or 리소스로 전송 data 암호화

대기 상태의 데이터는 서버측 암호화 및 클라이언트 측 아모화 기법으로 보호

### 서버측 암호화

서버측 암호화는 S3 플랫폼 내 진행,  
디스크에 저장될 때 data 객체를 암호화하고, 적절한 권한 증빙을 통해 data 인출 요청할 때 복호화해 전송

사용자 서버측 암호화의 세가지 옵션 하나 사용.

- AWS 기업용 표준 키 이용 암호화 및 복호화 각 단계 관리
- SSE-S3보다 고도화된 암호화 작업 서비스,  
엔벌로프 키(envelope key) 기법 이용 키 사용과 관련된 모든 작업 흐름을 추적해 감사 업무 활용.  
필요 따라 AWS KMS 서비스 통해 커스텀 키 임포트해 사용
- 커스텀 키 이용 S3 data 암호화 및 복호화 작업 수행

### 클라이언트측 암호화

AWS KMS-Managed Customer Master Key(CMK) 이용 S3 전송 전 data 암호화, data 객체 업로드 직전 data 키를 생성.  
Amazon S3 암호화 클라이언트 통해 Client-Side Master Key 사용

서버측 암호화는 클라이언트측 암호화 비해 복잡성 낮음, 대다수 사용자 선호하는 방법, 기업 및 기관에 따라 암호화 키를 직접 생성 및 관리하려는 경우, → 클라이언트측 암호화 사용할 것.

## 로그 관리

S3 각종 이벤트 추적 로그 파일 기록 남기는 것은 기본적으로 불능으로 설정. → S3 버킷의 작업이 워난 많이 이뤄지기 때문 S3 생성되는 로그 data 일일이 기록하는 것 효율적이지 않음

S3 로그 기능 활성화 소스 버킷과 테겟 버킷을 설정.  
또한 생성일 및 시간을 나타내는 접두사 및 분리기호 지정 다수의 소스 버킷 생성되는 다양한 로그 기록 좀 더 찾기 쉽게 만든 뒤 타켓 버킷 저장

S3 로그 생성 약간의 시간 지연 발생, 작업 세부 내역 정보

- 요청자의 계정 및 IP주소
- 소스 버킷 이름
- 요청 작업 내역(GET, PUT, POST, DELETE 등)
- 요청을 한 시간
- 요청에 대한 응답 상태

S3 버킷 CloudWatch 및 CloudTrail 등 다른 AWS 서비스 로그 및 객체 저장 위해 사용

# S3 내구성 및 가용성

S3 객체 저장 위해 다양한 스토리지 클래스 제공,  
어떤 조건에서도 data가 유지돼야 하는지 여부에 따라 신속하게 data 인출할 수 있는지 여부 따라, or 비용을 얼마나 절약할 수 있는지 여부 따라 클래스 선택적으로 사용

## 내구성

S3 내구성 99.999999999% 달하며 → 대부분 S3 클래스 및 Amazon Glacier 해당

저장 객체에 대한 연간 평균 순실 가능은 0.000000001%이며 → Amazon S3 10,000,000개 객체를 저장했을 때, 10,000년마다 단 하나의 객체가 손실 될 수 있는 확률 의미.

Source:aws.amazon.com/s3/faqs

다른 말로는 AWS 인프라가 실패하더라도 표준 S3/Glacier 플랫폼에 저장된 data의 손실 가능성은 사실상 0에 가까움

but. 중요한 data의 사본을 S3 버킷에만 저장하는 것은 바람직하지 못함.  
인프라 실패 외도 잘못된 환경설정, 계정 정보 분ㄴ실, 예기치 못한 외부 공격 등 저장된 data 대한 접근이 차단될 수 있는 가능성은 얼마든지 있음.

중요한 data는 항상 복수 장소에 백업해서 보관, → 서로 다르 서비스 및 미디어 타입 이용.

S3 제공 고도의 내구성은 S3 최소 세 개의 AZ, 가용성지역에 자동으로 data 복제해 놓기 때문에 가능. → 특정 지역에 있는 AWS 전체 시설 갑자기 지도에서 사라져도 data 사본은 다른 AZ 저장돼 있어 안전하다는 의미.

→ 내구성은 가용성 또는 비용 등의 요소와의 균형을 맞추기 위해 증가 또는 감소, 가급적 내구성 99.999999999% 이르는 표준 클래스 사용할 것 권장, 최소 3곳 이상의 AZ에 분산 저장되는 클래스 선택

예외로 S3 One Zone-IA 클래스이며, 단일 AZ에만 data 저장.  
→ 가용성이 약간 낮아짐

## 가용성

S3 객체의 가용성(avaliability)은 연간 객체 대한 지속적인 요청 처리할 수 있는 능력 퍼센트로 표시, Amazon S3 Standard 클래스 연간 99.999999999%의 응답 가능성 보증.  
→ 연간 9시간 미만 다운 타임이 발생. → 시간을 초과해서 발생하는 다운 타임에 대해서는 서비스 크레딧 적용

반면, S3 객체 내구성(durability)은 연간 data 손질 않고 보존될 수 있는 능력을 퍼센트로 나타냄, 모든 클래스에 대한 99.999999999% data 보호 능력 보증. → 사실상 data 손실 가능성 없다, 실제 문제가 발생해도 약간의 접속 지연 나타날 뿐

비교적 최근 도입된 S3 Intelligent-Tiering은 절약형 가용성 최적화 클래스로서, 클래스 내 data 대한 접근 빈도 모니터링해 지난 30일간연속적 data 대한 접근 없는 경우, 보다 낮은 요금 체계를 지닌 티어로  클래스 자동 변경. 사용자는 월간 자동화 요금을 부담

 

|  | S3 Standard | S3 Standard-IA | S3 One Zone-IA | S3 Intelligent-tiering |
| --- | --- | --- | --- | --- |
| 보증하는 가용성 | 99.99% | 99.9% | 99.5 | 99.9% |

## 종국적 일관성 데이터

S3 다수 지역 data 복제 사실 기억.  
→ 기존 객체를 업데이트하면 시스템 전체에 사실이 전파될 때까지 약간의 시간 지연 발생. 파일 새 버전 업로드한 직후 구 버전의 파일을 사전하면, 특정 위치에서는 이러한 변경 사항이 미처 전파되지 못하는 상화 발생.

단일 객체 대한 이와 같은 버전 충돌은 data 관리 및 애플리케이션 운영 심각한 부작용 초래할 수 있음, data는 종국적 일관성 표준(eventually consistent standard)에 따라 관리. 즉, data 상태 변경 대한 시간 지연을 감안한 뒤 관련 작업 수행 방식을 설계

업데이트 및 삭제 작업은 종국적 일관성 기준 적용, 새 객체의 생성 또는 PUT 같은 덮어쓰기 작업 쓰기 후 읽기 일관성(rad-after -write consistency) 기준 적용

# S3 객체 생애주기

S3 워크로드 중 상당 수 백업 아카이브 작업 수반.  
잘 설계뙨 백업 아카이브 작업 결과, 
점점 더 많은 백업 아카이브 정기적 누적

백업 아카이브 작업 기존 아카이브 버전 유지하는 일 중요, 스토리지 비용 및 공간 관리를 위해 구 버전 삭제하거나 폐쇄하는 작업도 필요, S3는 → 자동화된 백업 관리 기법인 버전 관리 및 생애주기 관기 기법 제공

## 버전 관리

다수 파일 시스템은 하나의 저장 공간에서 동일한 이름 붙은 파일을 여러 번 업데이트하며 새로운 파일 기존의 파일을 덮어쓰는 경우 많음.  
→ 사용자는 최신 버전의 파일 쓰면 됨. 때에 따라 기존 버전의 파일으르 가져와야할 때 있음, 실수에 의해 덮어쓰기된 파일 복구해야하는 경우

기본적으로 S3 저장된 객체 또한 비슷한 방식 관리, 버킷 레벨 버전 관리(versioning) 기능 활성화 객체 구 버전 저장해 두고 필요할 때 언제든 접속하도록 할 수 있음. → 실수에 의한 덮어쓰기 문제를 해소할 수 있긴 하지만 저장 공간 지나치게 커지는 문제를 낳기도 함.  
→ 해법 == 생애주기 관리

## 생애주기 관리

S3 Intelligent-Tiering 클래스 data 접속 빈도 따라 자동 클래스 변경, 버킷 레벨의 생애주기 규칙(lifecycle rules)을 작성 지정 일수 따라 자동 클래스 변경 설정.

ex. 처음 30일간 S3 Standard 클래스 객체 저장, 다음 30일간 좀 더 저렴한 One Zone IA 클래스 객체를 저장하는 생애주기 규칙 작성.  
→ 법규 등에 의해 오래된 data 1년간 추가 보관 경우, 365일간 Glacier 클래스 저장한 뒤 영구적 삭제 규칙 또한 추가

# S3 객체 접근하기

data 사용하지 않을 계획
→ 애초에 S3 파일을 저장하는 수고 하지 않았을 것

S3 data 저장하는 일만큼 S3 저장된 data 인출하는 일도 중요, 사업적 필요성 또는 보안적 필요성을 충족하는 유저에게만 data에 대한 접근 부여하는 일도 중여

## 접근 제어

새로 생성한 S3 버킷과 객체 마음대로 접속, 다른 AWS 계정 또는 외부 사용자는 결코 생성한 S3 버킷과 data 접속X  
→ 누군가에게 data 대한 접근 허용할 때 접근 제어 규칙(ACL)과 S3 버킷 정책, IAM 정책 통해 세분화된 접근 제어.

세 가지 접근 제어 기법 간에는 서로 약간씩 겹치는 영역 존재.  
그 중 ACL은 AWS가 IAM 도입하기 전 접근 정책.  
→ Amazon은 ACL 대신, S3 버킷 정책 IAM 정책 접근 제어 할 것 권장.

S3 버킷 정책 JSON 포맷 작성 뒤 S3 버킷에 부착, 다수 외부 계정 또는 유저가 하나의 S3 버킷 접근하기 위한 규칙 생성 주 활용.  
반면 IAM 정책은 IAM 기반 계정 레벨 접근 제어, 개별 유저 롤이 S3 포함한 다수 리소스 접근 위한 규칙 생성 활용

다음 코드 S3 버킷 정책 예시, root 유저 Steve 유저 S3 MyBucker라는 이름의 버킷 및 해당 콘텐츠에 접근. root 유저 Steve유저는 이 규칙에서 관리자(principats)로 간주

```
"Version" : "2021-10-17",
""Statement : [
"Efect" : "Allow",
"Principal" : {
"AWS" : ["arn:aws:iam: :xxxxxxxxxxxxx:root",
"["arn:aws:iam: :xxxxxxxxxxxxx:user/Steve"]
},
"Action" : "s3:*"
"Resource": ["arn:aws:s3:::MyBucket",
"arn:aws:s3:::MyBucket/*"]
}
]
}
```

날짜와 시간을 기준으로 버킷 정책을 생성해 접근 제한, CIDR 블록으로 특정 IP 주소 범위 접근 제한

이러한 정책을 IAM 개체에 부착하려면 다음과 같은 IAM 저액 작성, → 통해 위 S3 버킷 정채과 동일한 효과

버킷 정책 및 IAM 정책 이외 Amazon S3 Access Points를 이용 S3 버킷 내 객체 대한 유저 또는 서비스 접근 제어. 액세스 포인트 버킷 내 객체를 정의 호스트네임, 설정하는 내용에 따라 클라이언트는 호스트네임 통해 특정 객체 대한 읽기 또는 쓰기 권한 얻게 됨. 접근 허용 철회 더 이상 해당 객체 접근 X

액세스 포인트 요청하는 간단한 형식 AWS CLI 명령 대략 

```
aws s3control create-access-point --name my -vpc -ap\
	--accout-id 123456789012 --bucket my-bucket \
	--vpc-configuration VpcId=vpc-2b9d3c 
```

## 프리사인 URL

프라이빗 객체 대해 일시적으로 접근 허용 할 때 프라사인 URL(presigned URL) 생성 제공.   
CLI 이용 프로그래밍 기법 생성 프리 사인 URL 일정 시간 동안 유효, 시간 경과하면 접속 X

AWS CLI 명령 실행하면 접근 구너한 필요 문자열을 포함한 URL 반환된다.  
기본 설정 접근 권한 유효 시간 1시간이지만 아래 코드를 통해 허용된 접근 권한 유효 시간 10분

aws s3 presign s3://MybucketName/Private0bject —expires-in 600

## 정적 웹사이트 호스팅

S3 버킷은 정적 웹사이트를 위한 HTML 파일 호스팅에도 사용.  
정적 웹사이트란  
서버 측 아닌, 클라이언트 측 웹페잊 렌더링 및 스크립트 실행을 하는 웹사이트, 간단하고 단순하게 구성된 웹 문서를 클라이언트 브라우저에서 이용

저렴하면서 신뢰할 수 있는 플랫폼 S3 → 정적 웹사이트 호스팅에 적합  
S3 버킷을 정적 웹사이트 호스팅용 설정, 트래픽은 자동으로 index, html 등, 웹사이트 루트 문서 이동, 사용자가 HTML 페이지 내 링크 클릭 해당 페이지 또는 미디어로 이동, HTML 404 등 오류 발생 시 그에 적합한 페이지 이동

정적 웹사이트를 위해 [mysite.com](http://mysite.com)와 같은 DNS 도메인 네임이 필요한 경우, Amazon Route 53 버킷 엔드포인트 추가.  
단, 도메인 네임은 S3 버킷의 네임과 같아야함.  

또한 AWS Certificate Manager(ACM) 사이트 암호화 위한 SSL/TLS 인증 무료 받을 수 있음. → S3 버킷을 원본(origin) 하는 CloudFront 배포 임포트 사용

저장된 data 접근 또 다른 방법 S3 Select 및 Glacier Select.  
S3 Select는 SQL 스타일의 쿼리 기능 통해 효율적, 비용효율적으로 객체  관련 data 접근해 필요 부분 가져올 수 있음

대표적으로 사용 시나리오는 다수 소매 웹사이트 추출 영업 및 재고 data 를 포함한 대규모 CSV 파일의 검색 및 추출 이용.  
기업 마케팅 팀은 S3 Select 이용 특정 사이트 영업 및 재고 data 정기적 가져와 분석 활용

사용자 S3 Select 이용 전체 data 중 일부 특정 data를 추출함.  
data 접근 및 다운로드와 관련된 네트워크 부담 및 비용 부담 모두 줄임
